@InProceedings{10.1007/978-3-030-04497-8_10,
author="Gonz{\'a}lez-Gallardo, Carlos-Emiliano
and Torres-Moreno, Juan-Manuel",
editor="Batyrshin, Ildar
and Mart{\'i}nez-Villase{\~{n}}or, Mar{\'i}a de Lourdes
and Ponce Espinosa, Hiram Ered{\'i}n",
title="WiSeBE: Window-Based Sentence Boundary Evaluation",
booktitle="Advances in Computational Intelligence",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="119--131",
abstract="Sentence Boundary Detection (SBD) has been a major research topic since Automatic Speech Recognition transcripts have been used for further Natural Language Processing tasks like Part of Speech Tagging, Question Answering or Automatic Summarization. But what about evaluation? Do standard evaluation metrics like precision, recall, F-score or classification error; and more important, evaluating an automatic system against a unique reference is enough to conclude how well a SBD system is performing given the final application of the transcript? In this paper we propose Window-based Sentence Boundary Evaluation (WiSeBE), a semi-supervised metric for evaluating Sentence Boundary Detection systems based on multi-reference (dis)agreement. We evaluate and compare the performance of different SBD systems over a set of Youtube transcripts using WiSeBE and standard metrics. This double evaluation gives an understanding of how WiSeBE is a more reliable metric for the SBD task.",
isbn="978-3-030-04497-8"
}

